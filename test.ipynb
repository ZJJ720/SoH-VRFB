{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 40])\n",
      "torch.Size([1, 40])\n",
      "torch.Size([2, 41])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_features, output_size):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # 假设输入数据的形状为 (batch_size, channels, depth, sequence_length)\n",
    "        # 其中 sequence_length 是变化的\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(1, 3), stride=1, padding=(0, 1))\n",
    "        self.pool = nn.AdaptiveAvgPool2d((num_features, output_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        # 展平特征向量\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "# 定义模型参数\n",
    "num_features = 4  # 特征数量，与输入数据的channels一致\n",
    "output_size = 10  # 输出特征向量的统一长度\n",
    "\n",
    "# 创建模型实例\n",
    "model = SimpleCNN(num_features, output_size)\n",
    "\n",
    "# 假设有两个不同长度的4维列向量\n",
    "input1 = torch.randn(1, 1, 4, 25)  # 长度为15\n",
    "input2 = torch.randn(1, 1, 4, 20)  # 长度为20\n",
    "input3 = torch.randn(1,1)\n",
    "# 应用模型\n",
    "output1 = model(input1)\n",
    "output2 = model(input2)\n",
    "\n",
    "print(output1.shape)  # 应该是 (1, 40)\n",
    "print(output2.shape)  # 应该是 (1, 40)\n",
    "tensor_1 = torch.hstack((output1, input3))\n",
    "tensor_2 = torch.hstack((output2, input3))\n",
    "tensor_vstack = torch.vstack((tensor_1, tensor_2))\n",
    "print(tensor_vstack.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected np.ndarray (got numpy.int64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m     57\u001b[0m data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m42\u001b[39m)),\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m82\u001b[39m)),\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m122\u001b[39m))]\n\u001b[0;32m---> 58\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43munify_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 43\u001b[0m, in \u001b[0;36munify_dataset\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     41\u001b[0m x_set \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(x_set)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,num_features,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     42\u001b[0m x_set \u001b[38;5;241m=\u001b[39m model(x_set)\n\u001b[0;32m---> 43\u001b[0m y_set \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_set\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     44\u001b[0m data_set \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mhstack(x_set, y_set)\n\u001b[1;32m     45\u001b[0m results \u001b[38;5;241m=\u001b[39m data_set\n",
      "\u001b[0;31mTypeError\u001b[0m: expected np.ndarray (got numpy.int64)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_features, output_size):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # 假设输入数据的形状为 (batch_size, channels, depth, sequence_length)\n",
    "        # 其中 sequence_length 是变化的\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(1, 3), stride=1, padding=(0, 1))\n",
    "        self.pool = nn.AdaptiveAvgPool2d((num_features, output_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        # 展平特征向量\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    "def unify_dataset(data):\n",
    "    '''\n",
    "    读取数据列表 data，每个列表中的一个元素列表为一次放电周期，该元素列表的最后一个元素为输出数据，输入元素为 4 维列向量\n",
    "    首先读取列表中的每一个元素，将元素列表转化为 array 类型，分离输入和输出数据，并统一输入数据的形式\n",
    "    其次合并统一格式后的输入数据和输出数据，作为输出数组的第一个元素，其余以此类推\n",
    "    '''\n",
    "    # 定义模型参数\n",
    "    num_features = 4  # 特征数量，与输入数据的channels一致\n",
    "    output_size = 10  # 输出特征向量的统一长度\n",
    "\n",
    "    # 创建模型实例\n",
    "    model = SimpleCNN(num_features, output_size)\n",
    "\n",
    "    data_len = len(data)\n",
    "    for i in range(data_len):\n",
    "        data[i] = np.array(data[i])\n",
    "        if i == 0:\n",
    "            x_set = data[i][0:-1]\n",
    "            y_set = data[i][-1]\n",
    "            x_set = torch.from_numpy(x_set).float().reshape(1,1,num_features,-1)\n",
    "            x_set = model(x_set)\n",
    "            y_set = torch.from_numpy(y_set).float().reshape(1,-1)\n",
    "            data_set = torch.hstack(x_set, y_set)\n",
    "            results = data_set\n",
    "        else:\n",
    "            x_set = data[i][0:-1]\n",
    "            y_set = data[i][-1]\n",
    "            x_set = torch.from_numpy(x_set).float().reshape(1,1,num_features,-1)\n",
    "            x_set = model(x_set)\n",
    "            y_set = torch.from_numpy(y_set).float().reshape(1,-1)\n",
    "            data_set = torch.hstack(x_set, y_set)\n",
    "            results = torch.vstack((results, data_set))\n",
    "        \n",
    "        return results\n",
    "\n",
    "data = [list(range(1,42)),list(range(1,82)),list(range(1,122))]\n",
    "results = unify_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.4575, 6.6603, 7.0568, 6.7177, 6.6694, 7.0356, 6.7133, 6.6572, 7.0488,\n",
      "         6.9112, 6.6511, 7.0434, 6.8966, 6.5565, 7.0556, 6.8942, 6.5529, 7.0433,\n",
      "         6.8911, 6.5259, 7.0293, 6.8786, 6.5226, 6.8849, 6.8999, 6.4951, 6.8853,\n",
      "         6.8930, 6.5036, 6.7265, 6.5783, 6.5100, 6.6472, 6.9388, 6.4837, 6.6377,\n",
      "         6.9187, 6.4983, 6.6525, 7.0290, 1.2597],\n",
      "        [6.4322, 6.6443, 7.0099, 6.8578, 6.4792, 6.6177, 7.0090, 6.8747, 6.4681,\n",
      "         6.6890, 6.5353, 6.4543, 6.6083, 7.0003, 6.8228, 6.4482, 6.6050, 6.9685,\n",
      "         6.8427, 6.4819, 6.9655, 6.8407, 6.4488, 6.5957, 6.9683, 6.8073, 6.4234,\n",
      "         6.5676, 6.9405, 6.8069, 6.5331, 6.9302, 6.8222, 6.3881, 6.5493, 6.9161,\n",
      "         6.7930, 6.4301, 6.5668, 6.9362, 1.2627],\n",
      "        [6.5593, 6.6237, 6.6409, 6.6482, 6.6186, 6.6491, 6.6584, 6.6540, 6.6527,\n",
      "         6.7576, 6.2359, 6.6770, 6.6410, 6.6229, 6.6090, 6.6010, 6.5933, 6.5841,\n",
      "         6.6145, 6.5903, 6.6167, 6.5907, 6.6076, 6.5918, 6.6116, 6.5714, 6.5690,\n",
      "         6.5693, 6.5555, 6.5774, 6.5620, 6.5543, 6.5608, 6.5579, 6.5753, 6.5806,\n",
      "         6.6008, 6.6218, 6.5768, 6.5469, 1.1492],\n",
      "        [6.1871, 6.5431, 6.5536, 6.5424, 6.5152, 6.7538, 6.5635, 6.5768, 6.5564,\n",
      "         6.6719, 6.2203, 6.5831, 6.5603, 6.5651, 6.5176, 6.7887, 6.5783, 6.5891,\n",
      "         6.5380, 6.6612, 6.1997, 6.5814, 6.5507, 6.5609, 6.5241, 6.7836, 6.5448,\n",
      "         6.5597, 6.5745, 6.6744, 6.1588, 6.5402, 6.5409, 6.5513, 6.4972, 6.7501,\n",
      "         6.5444, 6.5367, 6.5528, 6.6426, 1.1483],\n",
      "        [6.5575, 6.5951, 6.5980, 6.3515, 6.6007, 6.6229, 6.9581, 6.6267, 6.6146,\n",
      "         6.6401, 6.6217, 6.6409, 6.6213, 6.6730, 6.6255, 6.6207, 6.4642, 6.6295,\n",
      "         6.6440, 6.6459, 6.6109, 6.6291, 6.6544, 6.9848, 6.6572, 6.6652, 6.4274,\n",
      "         6.6362, 6.6474, 6.7593, 6.2212, 6.6323, 6.6792, 6.4894, 6.6644, 6.6459,\n",
      "         6.7135, 6.6851, 6.6670, 6.5942, 1.0270],\n",
      "        [6.5777, 6.6489, 6.6761, 6.6729, 6.6803, 6.6956, 6.7021, 6.6940, 6.7192,\n",
      "         6.8113, 6.2382, 6.6937, 6.7074, 6.6960, 6.6957, 6.7203, 6.7015, 6.7226,\n",
      "         6.7235, 6.7244, 6.7055, 6.7183, 6.7058, 6.6966, 6.6828, 6.6957, 6.6918,\n",
      "         6.7086, 6.6966, 6.7205, 6.7119, 6.7203, 6.7004, 6.6799, 6.7303, 6.6996,\n",
      "         6.6839, 6.7088, 6.7187, 6.6996, 1.0281],\n",
      "        [6.2190, 6.5466, 7.2001, 6.9203, 6.2892, 7.2097, 6.9204, 6.2971, 6.5595,\n",
      "         7.1455, 6.2338, 6.5605, 7.1915, 6.9252, 6.2798, 7.2054, 6.9378, 6.3036,\n",
      "         6.5530, 7.1687, 6.2254, 6.5650, 7.2077, 6.9371, 6.2834, 7.1942, 6.9192,\n",
      "         6.2967, 6.5398, 7.1444, 6.2323, 6.5662, 7.1895, 6.9380, 6.2738, 7.1961,\n",
      "         6.9458, 6.2939, 6.5494, 7.1525, 0.9025],\n",
      "        [6.6490, 7.1121, 6.7114, 6.8207, 6.7774, 6.7698, 6.4940, 6.7628, 6.5551,\n",
      "         6.6800, 6.7035, 7.1366, 6.7278, 6.8091, 6.7498, 6.7489, 6.4570, 6.7243,\n",
      "         6.5399, 6.6892, 6.6544, 7.1533, 6.7580, 6.8087, 6.7257, 6.7379, 6.4416,\n",
      "         6.7351, 6.5521, 6.6759, 6.6540, 7.1352, 6.7199, 6.7682, 6.7209, 6.6978,\n",
      "         6.4513, 6.7158, 6.5301, 6.6625, 0.9057],\n",
      "        [6.2319, 6.5483, 7.1845, 6.6730, 6.5424, 7.2019, 6.6759, 6.5479, 7.2157,\n",
      "         6.9446, 6.5594, 7.2097, 6.9142, 6.3521, 7.1902, 6.9354, 6.3504, 7.2163,\n",
      "         6.9549, 6.2708, 7.1793, 6.9292, 6.3083, 6.9344, 6.9424, 6.2974, 6.9332,\n",
      "         6.9428, 6.3037, 6.6423, 6.4412, 6.2911, 6.5392, 6.9801, 6.2896, 6.5493,\n",
      "         6.9998, 6.2761, 6.5592, 7.1179, 0.7827],\n",
      "        [6.7197, 7.1875, 7.1902, 7.1911, 6.7698, 6.7703, 6.8543, 6.8443, 6.8560,\n",
      "         6.7753, 6.7461, 6.4892, 6.4842, 6.5230, 6.7565, 6.7760, 6.5673, 6.5984,\n",
      "         6.5629, 6.7254, 6.7059, 7.2114, 7.2170, 7.1944, 6.7831, 6.7795, 6.8658,\n",
      "         6.8532, 6.8502, 6.8095, 6.7416, 6.4896, 6.4838, 6.5063, 6.7839, 6.7798,\n",
      "         6.5482, 6.5784, 6.5893, 6.7125, 0.7845],\n",
      "        [6.6038, 6.4454, 6.6435, 7.1811, 7.1211, 6.6496, 6.4206, 6.6604, 7.1973,\n",
      "         7.1232, 6.5811, 6.4424, 6.6963, 7.2487, 7.1405, 6.6988, 6.4861, 6.6574,\n",
      "         7.1910, 7.1280, 6.5803, 6.4658, 6.6506, 7.2319, 7.1796, 6.7025, 6.4578,\n",
      "         6.6737, 7.2281, 7.1312, 6.5803, 6.4501, 6.6644, 7.2280, 7.1748, 6.6542,\n",
      "         6.4612, 6.6375, 7.1863, 7.1354, 1.0440],\n",
      "        [6.3773, 6.6761, 7.2010, 6.7551, 6.6730, 7.2230, 6.7487, 6.6768, 7.2037,\n",
      "         6.9954, 6.6718, 7.2109, 7.0142, 6.5283, 7.2121, 6.9951, 6.5323, 7.2167,\n",
      "         6.9790, 6.4514, 7.1909, 6.9999, 6.4632, 6.9878, 6.9973, 6.4606, 6.9654,\n",
      "         7.0153, 6.4554, 6.7540, 6.5778, 6.4449, 6.6579, 7.0428, 6.4529, 6.6679,\n",
      "         7.0397, 6.4395, 6.6748, 7.1757, 1.0470],\n",
      "        [6.6500, 6.5149, 6.7202, 7.2770, 7.2077, 6.7105, 6.4842, 6.7371, 7.2805,\n",
      "         7.1848, 6.6232, 6.5081, 6.7389, 7.2568, 7.1957, 6.7092, 6.4897, 6.7074,\n",
      "         7.2700, 7.1878, 6.6374, 6.4865, 6.7156, 7.2441, 7.2004, 6.7084, 6.4718,\n",
      "         6.6839, 7.2215, 7.1567, 6.6054, 6.4682, 6.6643, 7.2215, 7.1686, 6.6451,\n",
      "         6.4573, 6.6812, 7.2295, 7.1398, 1.0476],\n",
      "        [6.4019, 6.6676, 7.2000, 6.9799, 6.4619, 6.6809, 7.2103, 6.9806, 6.4597,\n",
      "         6.7946, 6.5587, 6.4508, 6.6823, 7.2050, 6.9742, 6.4425, 6.6638, 7.2122,\n",
      "         6.9799, 6.4577, 7.1763, 7.0025, 6.4497, 6.6672, 7.1966, 6.9917, 6.4601,\n",
      "         6.6750, 7.2128, 7.0049, 6.6563, 7.1924, 6.9895, 6.4529, 6.6808, 7.2189,\n",
      "         6.9928, 6.4735, 6.6758, 7.2018, 1.0482],\n",
      "        [6.2916, 6.9068, 6.9203, 6.4495, 7.1385, 6.3676, 6.9028, 6.9130, 6.4462,\n",
      "         7.0673, 6.2715, 6.8612, 6.8963, 6.4193, 7.0972, 6.3582, 6.8673, 6.8728,\n",
      "         6.4237, 7.0792, 6.2850, 6.8664, 6.8645, 6.4515, 7.0988, 6.3459, 6.8541,\n",
      "         6.8667, 6.4223, 7.0652, 6.2456, 6.8498, 6.8435, 6.3865, 7.0565, 6.3137,\n",
      "         6.8003, 6.8287, 6.3990, 7.0338, 1.0458],\n",
      "        [6.1763, 6.4469, 6.9701, 6.7375, 6.2270, 6.9577, 6.7422, 6.2200, 6.4046,\n",
      "         6.8975, 6.1265, 6.3830, 6.9213, 6.6954, 6.1981, 6.9119, 6.7198, 6.2148,\n",
      "         6.3815, 6.9039, 6.1070, 6.4004, 6.9000, 6.7272, 6.2037, 6.9052, 6.7151,\n",
      "         6.1966, 6.3632, 6.8829, 6.0844, 6.3473, 6.8737, 6.6866, 6.1760, 6.8877,\n",
      "         6.7031, 6.1476, 6.3055, 6.8040, 1.0410],\n",
      "        [6.1778, 6.2986, 6.1754, 6.1686, 6.4743, 6.4650, 6.6793, 6.6934, 6.2217,\n",
      "         6.2824, 6.1647, 6.1884, 6.4408, 6.4442, 6.6722, 6.6824, 6.2177, 6.2226,\n",
      "         6.1538, 6.1559, 6.3747, 6.4329, 6.6846, 6.6521, 6.2140, 6.1903, 6.1372,\n",
      "         6.1378, 6.3972, 6.5088, 6.2022, 6.6080, 6.2006, 6.2174, 6.1245, 6.1463,\n",
      "         6.3902, 6.3671, 6.6436, 6.6763, 1.0344],\n",
      "        [6.0815, 6.1826, 6.1745, 5.9467, 6.0774, 6.0904, 6.1406, 6.3527, 6.3571,\n",
      "         6.4376, 6.1823, 6.5861, 6.5938, 6.4387, 6.1554, 6.1500, 5.9648, 6.0784,\n",
      "         6.0641, 6.0637, 6.3129, 6.3372, 6.3034, 6.5893, 6.5778, 6.6056, 6.4820,\n",
      "         6.1098, 6.1365, 6.1869, 6.0752, 6.0592, 6.0623, 6.1110, 6.3524, 6.3134,\n",
      "         6.5932, 6.5486, 6.5453, 6.5170, 1.0267]], grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# 读取Excel文件，指定没有列标题\n",
    "df = pd.read_excel('data/test7.xlsx', header=None)\n",
    "\n",
    "# 初始化一个空列表来存储结果\n",
    "# 获取第六列的第一个元素作为输出数据\n",
    "output_data = df.iloc[:, 5].values\n",
    "data = []\n",
    "i = 0\n",
    "# 遍历 DataFrame，按第一列的数值进行分组\n",
    "for label, group in df.groupby(0):  # 0是第一列的索引位置\n",
    "    # 将第2到5列的数据转换为一维行向量\n",
    "    input_data = group.iloc[:, 1:5].values.flatten()\n",
    "    \n",
    "    # 将输入数据和输出数据拼接为一个新的行向量\n",
    "    row_vector = input_data.tolist() + [output_data[i]]\n",
    "    \n",
    "    # 将新的行向量添加到结果列表中\n",
    "    data.append(row_vector)\n",
    "\n",
    "    i=i+1\n",
    "\n",
    "\n",
    "# # 打印结果\n",
    "# element = data[-1]\n",
    "# element = np.array(element)\n",
    "# # print(element)\n",
    "# input_data = element[:-1].reshape(-1,4)\n",
    "# output_data = element[-1]\n",
    "# print(input_data)\n",
    "# print(output_data)\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_features, output_size):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # 假设输入数据的形状为 (batch_size, channels, depth, sequence_length)\n",
    "        # 其中 sequence_length 是变化的\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(1, 3), stride=1, padding=(0, 1))\n",
    "        self.pool = nn.AdaptiveAvgPool2d((num_features, output_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        # 展平特征向量\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "    \n",
    "\n",
    "# 定义模型参数\n",
    "num_features = 4  # 特征数量，与输入数据的channels一致\n",
    "output_size = 10  # 输出特征向量的统一长度\n",
    "\n",
    "# 创建模型实例\n",
    "model = SimpleCNN(num_features, output_size)\n",
    "\n",
    "data_len = len(data)\n",
    "for i in range(data_len):\n",
    "    data[i] = np.array(data[i])\n",
    "    if i == 0:\n",
    "        x_set = np.array(data[i][0:-1])\n",
    "        y_set = np.array(data[i][-1])\n",
    "        x_set = torch.from_numpy(x_set).float().reshape(1,1,num_features,-1)\n",
    "        x_set = model(x_set)\n",
    "        y_set = torch.from_numpy(y_set).float().reshape(1,-1)\n",
    "        data_set = torch.hstack((x_set, y_set))\n",
    "        results = data_set\n",
    "    else:\n",
    "        x_set = np.array(data[i][0:-1])\n",
    "        y_set = np.array(data[i][-1])\n",
    "        x_set = torch.from_numpy(x_set).float().reshape(1,1,num_features,-1)\n",
    "        x_set = model(x_set)\n",
    "        y_set = torch.from_numpy(y_set).float().reshape(1,-1)\n",
    "        data_set = torch.hstack((x_set, y_set))\n",
    "        results = torch.vstack((results, data_set))\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义Transformer模型\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_size, num_heads, num_layers, output_size):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.num_heads = num_heads\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # 编码器层\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=input_size, nhead=num_heads)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
    "\n",
    "        # 全连接层\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src的形状为 (seq_length, batch_size, input_size)\n",
    "        encoded = self.transformer_encoder(src)\n",
    "        # 取最后一个时间步的输出\n",
    "        output = self.fc(encoded[-1])\n",
    "        return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zjjtorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
