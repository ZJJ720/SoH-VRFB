{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 40])\n",
      "torch.Size([1, 40])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_features, output_size):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # 假设输入数据的形状为 (batch_size, channels, depth, sequence_length)\n",
    "        # 其中 sequence_length 是变化的\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(1, 3), stride=1, padding=(0, 1))\n",
    "        self.pool = nn.AdaptiveAvgPool2d((num_features, output_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        # 展平特征向量\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "# 定义模型参数\n",
    "num_features = 4  # 特征数量，与输入数据的channels一致\n",
    "output_size = 10  # 输出特征向量的统一长度\n",
    "\n",
    "# 创建模型实例\n",
    "model = SimpleCNN(num_features, output_size)\n",
    "\n",
    "# 假设有两个不同长度的4维列向量\n",
    "input1 = torch.randn(1, 1, 4, 25)  # 长度为15\n",
    "input2 = torch.randn(1, 1, 4, 20)  # 长度为20\n",
    "\n",
    "# 应用模型\n",
    "output1 = model(input1)\n",
    "output2 = model(input2)\n",
    "\n",
    "print(output1.shape)  # 应该是 (1, 40)\n",
    "print(output2.shape)  # 应该是 (1, 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取Excel文件，指定没有列标题\n",
    "df = pd.read_excel('data\\data1.xlsx', header=None)\n",
    "\n",
    "# 初始化一个空列表来存储结果\n",
    "# 获取第六列的第一个元素作为输出数据\n",
    "output_data = df.iloc[:, 5].values\n",
    "results = []\n",
    "i = 0\n",
    "# 遍历 DataFrame，按第一列的数值进行分组\n",
    "for label, group in df.groupby(0):  # 0是第一列的索引位置\n",
    "    # 将第2到5列的数据转换为一维行向量\n",
    "    input_data = group.iloc[:, 1:5].values.flatten()\n",
    "    \n",
    "    \n",
    "    # 将输入数据和输出数据拼接为一个新的行向量\n",
    "    row_vector = input_data.tolist() + [output_data[i]]\n",
    "    \n",
    "    # 将新的行向量添加到结果列表中\n",
    "    results.append(row_vector)\n",
    "\n",
    "    i=i+1\n",
    "\n",
    "# 打印结果\n",
    "print(results[-1][:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义Transformer模型\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_size, num_heads, num_layers, output_size):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.num_heads = num_heads\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # 编码器层\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=input_size, nhead=num_heads)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
    "\n",
    "        # 全连接层\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src的形状为 (seq_length, batch_size, input_size)\n",
    "        encoded = self.transformer_encoder(src)\n",
    "        # 取最后一个时间步的输出\n",
    "        output = self.fc(encoded[-1])\n",
    "        return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zjjtorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
